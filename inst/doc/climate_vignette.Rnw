\documentclass{article}
\title{Climarkplus Package}
\author{William Hughes}
\include{graphicsx}
\usepackage{float}

\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle

<<echo=FALSE>>=
library(climate)
options(digits = 2)
@ 


\begin{abstract}
A reimplimentation in R of some of the
concepts and methods of R. Stern's 
Climate package in Instat
extended to allow for more general
modelling

\end{abstract}


\section{Design}



\subsection{intro}

The package is not a port of the Climate
package for Instat and Genstat, written by R. Stern,
however, it is quite similar.

The major difference is that R does not have many
of the limitations of Instat.  As well the "spreadsheet
model", in which everything is more or less a matrix,
is only partially used.  In particular, the "list of
dataframes" was found to be useful.  As well, columns are
referred to by name, not number.

\section{Example}

\subsection{Data Set}

We will work with a dataset of 83 years of data from the
Zaza, Rawanda station.  This has been put into R form using
functions from Helen Greatrex.

<<>>=
data(zaza)
head(zaza)
tail(zaza)
@ 

It is useful to have a dataset with day of year (consistent in that March 1 is
day 61 for non leap years as well as leap years).  The function {\tt convert\_data}
does this.
<<>>=
zaza_doy=convert_data(zaza)
head(zaza_doy)
@

We can plot the average rain over the year (more on the details
of this later)
<<fig=TRUE>>=
 plot(sapply(split(zaza_doy$Rain,zaza_doy$DOY),mean,na.rm=T),
      ylab="mm Rain",xlab="Day of Year")
@

Note the rainfall has two peaks, but does not fall to 0 in Dec/Jan.

\subsection{Markov Model}
The first thing we do is to add the Markov lags, up to order=2.

<<>>=
zaza_wm=add_markov(zaza_doy)
#load("zaza_wm")
head(zaza_wm)
@

Note there are three new columns.  "d" means a dry day and
"w" means any day in which the amount of rain is more than
some threshold (default 0.12 mm).  Lag\_n is the pattern
of wet and dry days over the previous n days.

We can now count for each day of year:the number of "w" days following
two "d" days; the number of "w" days following a "d" then a "w"
day etc.  Dividing by e.g. the number of times we have two consecutive
"d" days give the estimated probability.  The function {\tt make\_all\_probs}
does this, for all lags up to order  (default 2).
As well, for each day of year, we determine the mean and standard
deviation of the rain of a "w" day both unconditional, and conditioned
on lags up to {\tt max\_mean\_rain\_order} (default 1)

<<>>=
#zaza_pbs=make_all_probs(zaza_wm)
load("/home/william/Reading/rstudio/climate/zaza_pbs")
head(zaza_pbs)
@

As we can see from a plot, the probabilities are all over the map.

<<fig=TRUE>>=
plot(zaza_pbs[,"P(w|ww)"],xlab="Day of Year",ylab="P(w|ww)")
@

This is due to the fact that the probabilities are based on
relatively few days.  Indeed for Jan 2, there were only 6
times when the previous two days were rainy.  However, we expect
that the probabilities on Jan 2 will be very similar to those
of Jan 3 and even something like the probabilities of Feb 4.
To achieve this we need to smooth the probabilities.  There are {\it many}
ways of doing this, the way used at present is to fit a Fourier series (this
has the advantage that we can make things periodic with period 1 year).
The order of the fit can be determined before hand or determined
interactively. The function used is {\tt make\_model\_ip}.

\subsection{Philosophy of Model}


<<>>=
   zaza_mod = make_model_pl(zaza_pbs,"/home/william/Reading/rstudio/climate/trunk/inst/parameter/order_2_0.pl")
@ 


The basic idea of the package is to model
and analyze rainfall.
To determine the amount of rainfall on a given day
we use two steps.



\begin{enumerate}
\item  Get the probability that there will be rain.
\item  Get the distribution of the amount of rain on rainy days
\end{enumerate}

Central to the package is the {\tt model} data set.  
There are functions to create models (e.g. from known data)
and functions that use the model to create simulated
data.  There are also functions that analyze real or simulated
data.

This is an example of a model data set.   This
model was created from real data of the rainfall at
a site in Rwanda. The data set has 366 rows,
only the first 6 are shown

<<>>=
head(zaza_mod)
@

I will attempt to explain the model

The info column contains information about the model.
(note everything here can and probably will change)
The first number is the order of the probability
of rain markov model, the third number is the order
of the Amount of rain (in mm) markov model.



\subsubsection{Probability of Rain}

We use a markov model of order k of the probability of rain, that is the chance
of rain will depend on the pattern of wet and dry days over the
previous k days. The order can be chosen (standard is an order of two,
e.g in the given model)

If the order is k, then there are $2^k$ possible patterns of
wet, w, and dry, d,  days.  For $k=2$ we have ww, dw, wd, dd.  Note for
every pattern there is a column in the model called $P(w|\mbox{pattern})$
For each day (the rows 1--366) we have the probability applicable to that
day.  There is no restriction on where these values come from. They can
(as in this case) be fitted values from raw data, however there are other
possibities.

\subsubsection{Amount of rain}

We use a markov model of order k for both the mean and standard deviation
of the amount of rain.  Hence, the mean and standard deviation of the ammount
of rain
will depend of the pattern of wet and dry days over the previous
k days.  The order can be chosen (standard is an order of 1, or 0
(do not take into account any pattern))

If the order is k, then there are $2^k$ possible patterns of
wet, w, and dry, d,  days.  For $k=1$ we have w, d  Note for
every pattern there is a column in the model called $<(r|\mbox{pattern}>)$
and a column called $sd(r|\mbox{pattern})$
For each day (the rows 1--366) we have the mean or the standard deviation
There is no restriction on where these values come from.
Note we also have the $<\mbox{rain}>$ and $sd(\mbox{rain})$ columns.
These are the unconditional mean and standard devation of the rain
amount.

Note though there is a day of year dependence in the
model there is (as yet) no year dependence.

\subsubsection{Obtaining Values: shape, offset}


Each column, whether probability or amount is said to be a "curve".
As indicated, the model does not know where the curve came
from.  However, it is often usefull to break the curve down
into two parts.  a "shape" and an "offset".   The shape is
any general curve, the offset is a single number applied to the shape
to get the final curve.  So
\begin{equation}
\mbox(curve) = \mbox{shape} + \mbox{offset}
\end{equation}
(We do not attempt to make a canonical offset for the shape.
We need the weighted sum of squares fit to a constant to be zero,
but in practice the weighting is not known)

The motivation here, is that it is often noted that higher order
curves (eg $P(w|\mbox{dw})$ ) are often very similar to lower
order curves  (eg $P(w|\mbox{d})$ ) but with an offset.   Thus,
it makes sense to estimate the higher order curve
by estimating only this offset, rather than the large number
of parameters needed to directly estimate the higher order curve.

An example can help here.   We look at the same site that was
used to produce the above model.

\begin{figure}[H]
\centering
\includegraphics{/home/william/Reading/rstudio/climate/compare_1.jpeg}
\end{figure}

The blue line is the probability of rain given that the previous
day was dry, $P(w|\mbox{d})$.   This can be broken down into
$P(w|\mbox{dd})$, the red line, and $P(w|\mbox{dw})$, the green line.
We note that the green line has much the same shape as the
blue line but with a substantial offset.

<<fig=TRUE,echo=FALSE>>=
off=get_offset(zaza_pbs[,"P(w|dw)"],zaza_pbs[,"#dw"],zaza_pbs[,"P(w|d)"],zaza_pbs[,"#w"])[[2]]
plot(fit_probs(zaza_pbs[,"P(w|d)"],zaza_pbs[,"#d"],order=4)[[1]]+off,
type="l",xlab="day",ylab="probability",col="blue",ylim=c(0,.8))
lines(fit_probs(zaza_pbs[,"P(w|dw)"],zaza_pbs[,"#dw"],order=4)[[1]],col="green")
@

Here we see $P(w|\mbox{d})$ (the blue line) shifted to match
$P(w|\mbox{dw})$ (the green line).  It seems that we can use
the shifted blue line rather than the green line.  Given that we have
much more confidence in the shifted blue line (more data, fewer coefficients)
that the green line, we may prefer to use the shifted blue line.

\section{Parameter Files and make\_model\_ip}

On way of creating a model is to start with a set of raw probabilities,
{\tt raw\_probs}, derived from a dataset associated (usually) with a station.
Then each curve $P(w|\mbox{lag})$ can be a fitted version of the corresponding
data in the dataset, or a (possibly shifted) fitted version of some other
data from the dataset.

The model is described by a {\tt parameter (*.pl)} file.
An example of the start of such a file is given.

\begin{verbatim}
<order> = 2
<dd> = dd  
<dd_fit_order>= choose
<dd_offset> = NO
...
\end{verbatim}

Every line has the form
\begin{verbatim}
<key> = value
\end{verbatim}
When read in you get a list, with {\tt list[key] = value}
with value a string.

The first parameter, {\tt order}, gives the order of the wet/dry part
of the model.  For each of the $2^{\mbox{order}}$ values for the {\tt lag},
there are three parameters.   The first {\tt lag} is the column
of the raw dataset used; the second {\tt lag\_fit\_order} is the number
of harmonics used to fit the raw data (if this value is {\tt choose} then the fit
order is determined automatically); the third {\tt lag\_offset}
is the dataset from which the offset is to be determined, if the
value is {\tt NO} then there is no offset.

The part of the parameter file which deals with the amount of rain on wet
days is similar,  although in this case we have {\tt lag} and {\tt lag\_sd}
for the mean and standard deviation.

\begin{verbatim}
<rain_order>= 1
<rw>=w
<rw_fit_order>=4
<rw_offset> = NO
<rw_sd>=w
<rw_sd_fit_order>=choose
<rw_sd_offset> = NO
...
\end{verbatim}

This is the "standard" parameter file, {\tt order\_2\_0.pl}.   It describes an order 2
model for the probability of rain, and an order zero model for the
amount of rain.

\begin{verbatim}
<order> = 2
<dd> = dd  
<dd_fit_order>= choose
<dd_offset> = NO
<dw> = dw
<dw_fit_order>= choose
<dw_offset> = NO
<wd>= wd
<wd_fit_order>= choose
<wd_offset> = NO
<ww> = ww
<ww_fit_order>= choose
<ww_offset> = NO

rain_order>= 0
<r0_fit_order>= 4
<r0_sd_fit_order>= 4

\end{verbatim}

If we want an order 1 model for the amount of rain, we change only
the rain section (last three line) to 

\begin{verbatim}
<rain_order>= 1
<rw>=w
<rw_fit_order>=4
<rw_offset> = NO
<rw_sd>=w
<rw_sd_fit_order>=4
<rw_sd_offset> = NO
<rd>=0
<rd_fit_order>=4
<rd_offset> = NO
<rd_sd>=0
<rd_sd_fit_order>=4
<rd_sd_offset> = NO
\end{verbatim}

We can get a mixed markov model by  changing what is used to estimate
higher order lags.

\begin{verbatim}
<order> = 2
<dd> = d  
<dd_fit_order>= choose
<dd_offset> = NO
<dw> = d
<dw_fit_order>= choose
<dw_offset> = NO
<wd>= wd
<wd_fit_order>= choose
<wd_offset> = NO
<ww> = ww
<ww_fit_order>= choose
<ww_offset> = NO


<rain_order>= 0
<r0_fit_order>= 4
<r0_sd_fit_order>= 4
\end{verbatim}

Note that the curves for the order two lags dd and dw are both derived 
from the order 1 curve lag d.  However the curves for the order 2
lags wd and ww are derived from order two curves.  In other words we only
use order 2 lags if the first day is wet.

We can add offsets if desired.  Let us change the offset for the curve
for lag dw.

\begin{verbatim}
<dw> = d
<dw_fit_order>= choose
<dw_offset> = dw
\end{verbatim}

Note that we still derive the curve from the first order lag,
but now we add an offset derived from the second order lag.

We can illustrate this by using the above data set.
(here we are looking a only the probability of rain)

First we show a second order model

<<fig=TRUE>>=
mod=make_model_pl(zaza_pbs,"/home/william/Reading/rstudio/climate/trunk/inst/parameter/order_2_0.pl")
plot_model(mod,"Second Order Model")
@

As we have noted above, the wd, and ww, lines are not close
in shape to the w line, but the dd and dw lines are close in
shape to the d line.   So we can try a mixed model, going
to order 2 lags if the previous day was wet, but using only
order 1 if the previous day was dry

<<fig=TRUE>>=
mod=make_model_pl(zaza_pbs,"/home/william/Reading/rstudio/climate/trunk/inst/parameter/order_2_(2_1)_0.pl")
plot_model(mod,"Mixed Model (wet 2, dry 1) ")
@

Note that {\tt P(w|dw)} and {\tt P(w|dd)} are identical.  The latter
obscures the former.

We note from above that the d line can be used for dd
but while the dw line is similar in shape to dd there is an
obvious offset.   We can include this offset.

<<fig=TRUE>>=
mod=make_model_pl(zaza_pbs,"/home/william/Reading/rstudio/climate/trunk/inst/parameter/offset.pl")
plot_model(mod,"Mixed Model (wet 2, dry 1) dw offset")
@


\subsection{smoothing}


When fitting to obtain the model , we weight each estimate by the number of observations used to
obtain the estimate.  So estimates based on only a single day (e.g. two
consecutive "w" days during the dry season) are not given much weight.   

<<fig=TRUE>>=
plot(zaza_mod[,"P(w|ww)"],xlab="Day of Year",ylab="P(w|ww)")
@

And things look much smoother.   


We can also do the fitting interactively.  At the console, enter the command
<<eval=FALSE>>=
zaza_mod = make_model_general(zaza_pbs,inter=TRUE)
@
We see a graph 

\begin{figure}[h!]
\centering
\includegraphics{/home/william/Reading/rstudio/climate/inter_plot1.jpeg}
\end{figure}

The red circles represent data points.  The are of each circle is proportional
to the weighting the data point has in the fit.  The smallest circles are
data point calculated from a single line of the raw data 
(so for probabilities are 0 or 1).

The blue line represents the fitted curve.  It will change when we change
the order of the Fourier fit.

On the console you will see:

\begin{figure}[h!]
\centering
\begin{verbatim}
enter

a:  use this fit
b:  use previous order
f:  add one to order
k:  set order to k
\end{verbatim}
\end{figure}
To enter a value you must type the value into the console and then press
return.  Entering a number changes the fit order to that number.  Try entering
8.  You get:

\begin{figure}[H]
\centering
\includegraphics{/home/william/Reading/rstudio/climate/inter_plot2.jpeg}
\end{figure}

The fit does not look that much better, especially when considering
how much more wavy the line is.  Try entering 1.  You get:

\begin{figure}[H]
\centering
\includegraphics{/home/william/Reading/rstudio/climate/inter_plot3.jpeg}
\end{figure}


Clearly we are now underfitting.   Enter 4, to get back to the first graph,
then enter {\tt a} to accept this fit.  You will then have 5 more graphs
to fit. Play around with the {\tt a,b} and {\tt f} keys or enter numbers.
Repeatedly pressing {\tt a} will use the default.

\subsection{Synthetic Data}

Once we have a model, we can use it to synthesize data.  The command is

<<>>=
#load("zaza_synth")
zaza_synth=synth_data_set_mod(zaza_mod,num_years=83)
head(zaza_synth)
@
The data will start from year 1970 by default.  The number
of years produced is limited by your patience (and by the address space of your
machine,  200,000 years for a 32 bit machine; you need to have a {\bf LOT} of patience to reach the limit if you 
have a 64 bit machine).
As a rule of thumb 1000 years takes about a minute (your mileage will vary).

Let's compare the synthetic and the real data.  Clearly we cannot expect
day by day comparisons to be equal, indeed, compare the rain in 1931, to the first year of rain in the synthetic data.

<<fig=TRUE>>=
plot(zaza$Rain[93:459],xlab="Day of Year",ylab="mm Rain")
points(zaza_synth$Rain[1:366],col="green")
@

The exact values are different, but the pattern is similar.
We now take advantage of the r function {\tt x\_split=split(x,y)}
where x and y are in the same dataframe.  What this gives is a list
indexed by the values of y.  Each element contains every value
of x with the given value of y.  So {zaza\_split=split(zaza\_doy$Rain,zaza\_doy$DOY)}
is a list of 366 vectors. {\\tt zaza\_split[["120"]]} is a vector of all rainfall
on Day of Year 120.  So {\tt mean(zaza\_split[["120"]],na.rm=TRUE)} is the mean
rainfall on day 120 (the last arg means ignore NA's).  We take further advantage by using the r function {\tt sapply(list, function,args)} which applies  function
to every element of list, passing args to function.  So
{\tt sapply(zaza\_split,mean,na.rm=TRUE)} is a vector of the average rainfalls.
Comparing

<<fig=TRUE>>=
zaza_split=split(zaza_doy$Rain,zaza_doy$DOY)
synth_split=split(zaza_synth$Rain,zaza_synth$DOY)
plot(sapply(zaza_split,mean,na.rm=TRUE),xlab="Day of Year",
     ylab="Average Rain mm.")
points(sapply(synth_split,mean,na.rm=TRUE),col="green")
@

The fit looks good.
\subsection{Yearly Stats}

If we split our real or synthetic data set by {\tt mod\_year}
then we get a list of datasets, each covering a specific year. We can then
find things such a the average spell length (over years), the maximum dry spell
for each year etc.  There is a simple function to split by {\tt mod\_year}
adding it if it does not exist.  The function {\tt add\_spell\_info} calculates
and adds the length of wet and dry spells.
This should be applied before splitting if spells should cross year boundaries.
Note that we need to add the Markov stuff before adding spell info.

<<>>=
synth_wm= add_markov(zaza_synth)
synth_spell= add_spell_info(synth_wm)
zaza_spell=add_spell_info(zaza_wm)
synth_split=split_by_year(synth_spell,year_begins_in_july=TRUE)
zaza_split=split_by_year(zaza_spell,year_begins_in_july=TRUE)
length(synth_split)
head(synth_split[["1981"]])
nrow(synth_split[["1981"]])
length(zaza_split)
head(zaza_split[["1951"]])
nrow(zaza_split[["1951"]])
@

So  {\tt synth\_split} consists of 84 data sets (there is a partial
year at the beginning and end) and {\tt zaza\_split}
consists of 82 data sets (there are no partial years.)

\subsubsection{Spell Lengths}

We can look at the average dry spell length.  For this we use the data
that has not been spit into years.  First we take only dry spells.
To do this, take only rows of {\tt zaza\_spell} that correspond to a dry
day.  

<<>>=
zaza_dry=zaza_spell[(zaza_spell$wet_or_dry=="d"),]
head(zaza_dry)
@

Now we split the spell lengths by day of year, 
then take the mean (ignoring NA's).  Plot this

<<fig=TRUE>>=
dry_spell_split=split(zaza_dry$spell_length,zaza_dry$DOY)
plot(sapply(dry_spell_split,mean,rm.na=T),type="l",xlab="Day of Year",
     ylab="Days",main="Mean Length of Dry Spell")
@

Note this is the average length of a dry spell, given that there
is a dry spell.  This may or may not be what you want.  If you want
the mean dry spell length, taking the dry spell length of a wet day
to be 0 then this can be done by adding another column.

<<fig=TRUE>>=
zaza_spell$dry_spell_length=zaza_spell$spell_length
zaza_spell$dry_spell_length[zaza_spell$wet_or_dry == "w"]=0
zaza_spell$dry_spell_length[is.na(zaza_spell$wet_or_dry)]=NA
zaza_spell_dry_split=split(zaza_spell$dry_spell_length,zaza_spell$DOY)
plot(sapply(zaza_spell_dry_split,mean,na.rm=T),type="l")
@
This looks similar.  Plot them together for comparison.  (note the use of
the {\tt lines} function which adds lines to a graph)

<<fig=TRUE>>=
plot(sapply(dry_spell_split,mean,rm.na=T),type="l",xlab="Day of Year",
     ylab="Days",main="Mean Length of Dry Spell")
lines(sapply(zaza_spell_dry_split,mean,na.rm=T),col="green")
@

Assume that we know our crop can withstand dry spells of up to 
5 days.  Then we are interested in the probability of a dry spell
of more than 5 days.  

<<fig=TRUE>>=
zaza_dry_spell_over_5=zaza_spell[zaza_spell$wet_or_dry=="d" & zaza_spell$spell_length > 5,]
zaza_dry_spell_over_5_split=split(zaza_dry_spell_over_5,zaza_dry_spell_over_5$DOY)
num_of_dry_spells_over_5=sapply(zaza_dry_spell_over_5_split,nrow)
zaza_spell_good=zaza_spell[!is.na(zaza_spell$wet_or_dry),]
zaza_spell_good_split=split(zaza_spell_good,zaza_spell_good$DOY)
num_good_days=sapply(zaza_spell_good_split,nrow)
prob_of_dry_spell_over_5=num_of_dry_spells_over_5/num_good_days
plot(prob_of_dry_spell_over_5,type="l",xlab="Day of Year",ylab="prob",
       main="Probability of a dry spell of more than 5 days")
@

Naturally, all the above can be done with synthetic data as well.
(Indeed, this is the whole point.  Get your model from 20 years of
real data, but get your probabilities from 100 or 1000 years of
synthesized data.  In some cases, the actual value can be obtained
from the model by clever analysis (e.g. Markov model's and spell probabilities). 
However, R is cheap and fast; Statisticians capable of doing the analyses
are expensive and slow.  And what happens when you modify your
model?)

\subsubsection{First Day of Growing Season}

Two common definitions of the "First Day of the Growing Season" are:

\begin{enumerate}
\item  The first day of a period of n rainy days on which there is more than k
millimetres of rain in total
\item  As (1.) but additionally, there is no dry spell of k days in the next
j days
\end{enumerate}

The second definition may be defined as the time of successful planting
(young seedlings may be injured or killed by a dry spell of k days)
The function {\tt fdgs} can calculate either of these for a year
of data.  So if we apply it to every year of data to find the distribution
of the "First Day of the Growing Season"  (we start our search in July
if the growing season occurs in "winter").  So:

<<>>=
first_days=sapply(zaza_split,fdgs)
first_days_succ=sapply(zaza_split,fdgs,type=2)
@

and we can do the same thing with synthetic data

<<>>=
first_days_synth=sapply(synth_split,fdgs)
first_days_succ_synth=sapply(synth_split,fdgs,type=2)
@

In this case a histogram is best for viewing a comparison.

<<fig=TRUE>>=
hist(first_days,breaks=25,col="red",density=10,
     xlab="Day of Year",main="First Day of Growing Season")
@
We can compare this with the calculations from the synthetic data
(note for adding information to a histogram, use the {\tt add=T})
parameter.

<<fig=TRUE>>=
hist(first_days,breaks=25,col="red",density=10,
     xlab="Day of Year",main="First Day of Growing Season")
hist(first_days_synth,breaks=25,col="green",density=5,add=T)
@

Again, this is similar but not identical.

Another question we might ask is:  "In how many of the 82 years
was planting by definition 1. successful?"
To answer this we can compare, {\tt first\_days}
and {\tt first\_days\_succ}.  We need to be careful to allow
for NA's and for modding by 366.

<<>>=
diff=(first_days_succ-first_days) %% 366
diff_no_na=diff[!is.na(diff)]
diff_good=diff_no_na[diff_no_na==0]
length(diff_good)/length(diff_no_na)
@

This suggests that the default values do not work
well for this site. Perhaps a more drought tolerant crop
would work better, or wait for more rain before saying
the growing season has started.

\section{Mixed order Markov Models}

<while this section is still accurate in that {\tt make\_model\_general}
sill exists and works, the functionality of {\tt make\_model\_general}
is not in the more general {\tt make\_model\_pl}.  The theoretical
stuff is still applicable.>

Examination of the different fits shows that the order needed in the markov
model can vary for different patterns of wet and dry days.  E.g.  It may
be that the probability of a wet day given that the previous day was wet
is not different if it was wet two days ago or if it was dry two days ago.
However, at the same time, it may be that the probability of a wet day, given
that the previous day was dry does depend on whether it was wet or dry two
days ago.  In symbols
\begin{equation}
P(w|wd)=P(w|ww)=P(w|w)
\end{equation}
but
\begin{equation}
P(w|dd) \neq P(w|dw) \neq P(w|d)
\end{equation}

To handle these type of cases a mixed markov model, has been created.
This is just a list, the first element is the order. (This is the maximum
of the order for wet days and dry days) There
follow $2^{\mbox{order}}$ strings, each named for one of the
possible lag patterns.  To use the model you simply index by the lag
pattern and the model will tell you which lag to actually use.
E.g. Let m be the mixed markov model for the above case.
We have
\begin{equation}
m[1]=2, m["wd"]="w", m["ww"]="w", m["dw"]="dw", m["dd"]="dd"
\end{equation}
The model is characterized by two variables {\tt max\_w\_order} and
{\tt max\_d\_order}.  In the above case these have the values 1 and 2
respectively.  Similarly, there are two variables {\tt max\_rain\_w\_order}
{\tt max\_rain\_d\_order}, which deal with, not if there is going to be rain,
but the mean and standard deviation of the amount of rain, given that
the day is wet.  

All variables are parameters to the function {\tt make\_model\_general}.
The values are stored as part of the model produced.  To use this function
you must first call {\tt make\_all\_probs} which requires a data set with
markov lags added by {\tt add\_markov}.  Both of these functions take
one or more order parameters.  If these orders are less that the highest
order used by {\tt make\_model\_general} the function will fail.
As an example

<<>>=
#load("zaza_wm_3")
zaza_wm_3=add_markov(zaza_doy,order=3)
#load("zaza_all_pbs")
zaza_all_pbs=make_all_probs(zaza_wm_3,max_rainy_day_order=3,
                            max_mean_rain_order=2)
head(zaza_all_pbs)
zaza_mod=make_model_general(zaza_all_pbs,max_w_order=1,max_d_order=3,
                            max_rain_w_order=1, max_rain_d_order=2)
head(zaza_mod)
@

The model, {\tt zaza\_mod}, uses a lag of 1 for wet days and
a lag of 3 for dry days.  So if the previous day was wet, then the 
probability that today will be wet does not depend on what happened
before this.  On the other hand if the previous day was dry, then the
probability that today will be wet depends on what happened two days
ago and three days ago.  Similarly, if the previous day was wet,
then the amount of rain will not depend on what happened two days
ago, if the previous day was dry it will.

Note the maximum lag was 3 days, so {\tt add\_markov} needs an
order of 3.  We use 3 as {\tt max\_d\_order} so {\tt max\_rainy\_day\_order}
has to be 3.  However, the largest of the {\tt max\_rain} orders is 2
so {\tt max\_mean\_rain\_order} only needs to be 2.   There is no harm
in making the orders to large in {\tt make\_all\_probs} but the function
will run more slowly for larger orders.

The question arises naturally, how do we determine the order
needed.  This very important question is not addressed by the package
(yet).

appendix
%\addcontentsline{toc}{chapter}{Appendix}
%\addtocontents{toc}{\protect\contentsline{chapter}{Appendix:}{}}

\section{Details of Design}
\subsection{overview}




The package is based on a number of major objects
(not, or at least not yet, objects in the sense of
object oriented programming)

The basic idea is to take your data, put it in the form of a data set
(the most important thing is that leap years are handled consistently)
get the needed markov probabilities in raw form (a probability set)
then smooth/fit these to get a (mixed) markov model.  This can
be used to synthesize a data set of arbitrary length, which
can then be analyzed.

A {\bf data set} is a data frame with columns for the station, the date, the day
of year, the amount of rain and possibly others.      Some commands
(e.g. {\tt add\_markov}, {\tt add\_spell\_info} {\tt add\_dmy})
take a standard data set and add columns to it.  There is an order here,
e.g. {\tt add\_spell\_info} needs to know if a day is wet or dry so you need
to run {\tt add\_markov} first, but it is not necessary to run {\tt add\_dmy}
first (though you may wish to run this in order to get monthly breakdowns
of the spell info).

A {\bf probability set} contains the conditional probabilities of a wet
day (a day with some rain) and conditional means and standard deviations
of the rain on rainy days.  All conditions are past patterns, lags, of wet and
dry days.  A probability set is created from a data set with markov information
(added by  {\tt add\_markov}) by the function (\tt make\_all\_probs)

A {\bf model} contains all the information needed to create a synthetic
data set (using the function {\tt synth\_data\_set\_mod}).  At present
a model is a data frame but this may change.

\subsection{major objects}

\begin{description}
\item[data set (needed columns)]  A data set is a data frame with at least the following columns
    \begin{description}
    \item[Station]  The station for the data
    \item[Date]  The date of a single day in yyyy/mm/dd format
    \item[Rain]  The amount of rainfall in mm
    \item[DOY]  The day of the year
    \end{description}
    Every year will have 366 days.  If the year is a leap year day 60
    will be Feb 29, if not day 60 has a NA date and an NA rain.  For any year
    day 61 is March 1.  The function {\tt convert\_data} will take
    any data set with columns Station, Rain and Date, and make this form.
    

    Eventually there may be other needed columns in a data set
\item[data set (optional columns)]    A data set may or may not have the following
columns  (they are needed for certain operations)
     \begin{description}
     \item[wet\_or\_dry and lags]  The column {\tt wet\_or\_dry} contains "w" or "d" depending on whether the rainfall is above a threshold (.12mm by default).
     The lags up to order n (default 2) are a string or n w's or d's and
     record what happened on the previous days.  These columns can be
     added by {\tt add\_markov}
     \item[first\_DOY and spell\_length]  These two columns are used to indicate
     the length of wet and dry spells.  A spell is any number of consecutive
     w or d days, or a single NA day.  For each row {\tt first\_DOY} and
     {\tt spell\_length} refer to the current spell.   These columns can be added
     by {\tt add\_spell\_length}
     \end{description}
\item[Probability set]  A data frame with 366 rows and the following columns
     \begin{description}
     \item[P(w)]  The probability of rain on the day.
     \item[<rain>]  The average amount of rain on rainy days
     \item[sd(rain)] The standard deviation of rain on rainy days
     \item[ \# days, \# wet days]  Use the same threshold as {\tt add\_markov}
     \item[P(w|lags)]  The probability that the day is w given that the lag
     is {\tt lags}
     \item[\# lag]  The number of times this lag was seen on this day
     \item[<(r|lag)> sd(r|lag)]  Mean and standard deviation of rainfall
     conditioned on lag.
     \item[\# r lag]  The number of rainy days for which the given lag
     was seen
     \end{description}
     A probability set can be created from a data set with markov info using
{\tt make\_all\_probs}
\item[Model]  A model from which data sets can by synthesized.  Nothing is stable,
but this is almost sure to change in some ways.  At present it is a data set
with 366 rows and  the following columns
     \begin{description}
     \item[info]  Row 1, higher order, Row 2, order used for wet days, Row 3  order used for dry days, Other rows  NA  (This will be added to as needed)
     \item[P(w|lag)]  The conditional probability of rain given lag
     \item[<rain> sd(rain)] mean and standard deviation of rain on rainy days
     \end{description}
     A model can be made from a probability set using {\tt make\_model\_pl}
     
\end{description}

\end{document}
