\documentclass{article}
\title{Climarkplus Package}
\author{William Hughes}
\include{graphicsx}
\usepackage{float}

\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle

<<echo=FALSE>>=
library(climarkplus)
options(digits = 2)
@ 


\begin{abstract}
A reimplimentation in R of some of the
concepts and methods of R. Stern's 
Climate package in Instat
extended to allow for more general
modelling

\end{abstract}


\section{Design}



\subsection{intro}

The package is not a port of the Climate
package for Instat and Genstat, written by R. Stern,
however, in some ways it is quite similar

The major difference is that fitting is done
using a generalized linear model on the unbinned
data rather than to estimated probabilities.
Modifications to the basic Markov model
can be made (e.g. a time term) and evaluated.

Other differences include the fact that R does not have many
of the limitations of Instat.  and  the "spreadsheet
model", in which everything is more or less a matrix,
is only partially used.   Columns are
referred to by name, not number.

\section{Example}

\subsection{Data Set}

We will work with a dataset of 83 years of data from the
Zaza, Rawanda station.  This has been put into R form using
functions from Helen Greatrex.

<<>>=
data(zaza)
head(zaza)
tail(zaza)
@ 

It is useful to have a dataset with day of year (consistent in that March 1 is
day 61 for non leap years as well as leap years).  The function {\tt convert\_data}
does this.
<<>>=
zaza_doy=convert_data(zaza)
head(zaza_doy)
@

We can plot the average rain over the year (more on the details
of this later)
<<fig=TRUE>>=
 plot(sapply(split(zaza_doy$Rain,zaza_doy$DOY),mean,na.rm=T),
      ylab="mm Rain",xlab="Day of Year")
@

Note the rainfall has two peaks, but does not fall to 0 in Dec/Jan.

\subsection{Markov Model}
The first thing we do is to add the Markov lags, up to order=2.

<<>>=
zaza_wm=add_markov(zaza_doy)
#load("zaza_wm")
head(zaza_wm)
@

<<echo=FALSE>>=
#we need this for an example so make now
#zaza_pbs=make_all_probs(zaza_wm)
load("/home/william/Reading/rstudio/climate/zaza_pbs")
@

Note there are three new columns.  "d" means a dry day and
"w" means any day in which the amount of rain is more than
some threshold (default 0.12 mm).  Lag\_n is the pattern
of wet and dry days over the previous n days.

\subsection{Philosophy of Model}

The basic idea of the package is to model
and analyze rainfall.
To determine the amount of rainfall on a given day
we use two steps.



\begin{enumerate}
\item  Get the probability that there will be rain.
\item  Get the distribution of the amount of rain on rainy days
\end{enumerate}


\subsubsection{Probability of Rain}

We use a markov model of order k of the probability of rain, that is the chance
of rain will depend on the pattern of wet and dry days over the
previous k days. The order can be chosen (standard is an order of two,
e.g in the given model)

If the order is k, then there are $2^k$ possible patterns of
wet, w, and dry, d,  days.  For $k=2$ we have ww, dw, wd, dd.  Note for
every pattern there is a column in the model called $P(w|\mbox{pattern})$
For each day (the rows 1--366) we have the probability applicable to that
day.  There is no restriction on where these values come from. They can
be fitted values from raw data, however there are other
possibities.

\subsubsection{Amount of rain}

We use a markov model of order k for both the mean of the rain.  Hence, the mean ammount
of rain
will depend of the pattern of wet and dry days over the previous
k days.  (It is assumed that the amount of rain follows a Gamma distribution
with a constant shape)  
The order can be chosen (standard is an order of 1, or 0
(do not take into account any pattern))

If the order is k, then there are $2^k$ possible patterns of
wet, w, and dry, d,  days.  For $k=1$ we have w, d  Note for
every pattern there is a column in the model called $<(r|\mbox{pattern}>)$.
For each day (the rows 1--366) we have the mean.
There is no restriction on where these values come from.
Note we also have the $<\mbox{rain}>$ column
This is the unconditional mean of the rain
amount.

Note though there is a day of year dependence in the
model there is (as yet) no year dependence.

\subsubsection{Obtaining Values: shape, offset}


Each column, whether probability or amount is said to be a "curve".
As indicated, the model does not know where the curve came
from.  However, it is often usefull to break the curve down
into two parts.  a "shape" and an "offset".   The shape is
any general curve, the offset is a single number applied to the shape
to get the final curve.  So
\begin{equation}
\mbox(curve) = \mbox{shape} + \mbox{offset}
\end{equation}
(We do not attempt to make a canonical offset for the shape.
We need the weighted sum of squares fit to a constant to be zero,
but in practice the weighting is not known)

The motivation here, is that it is often noted that higher order
curves (eg $P(w|\mbox{dw})$ ) are often very similar to lower
order curves  (eg $P(w|\mbox{d})$ ) but with an offset.   Thus,
it makes sense to estimate the higher order curve
by estimating only this offset, rather than the large number
of parameters needed to directly estimate the higher order curve.

An example can help here.   We look at the same site that was
used to produce the above model.

\begin{figure}[H]
\centering
\includegraphics{/home/william/Reading/rstudio/climate/compare_1.jpeg}
\end{figure}

The blue line is the probability of rain given that the previous
day was dry, $P(w|\mbox{d})$.   This can be broken down into
$P(w|\mbox{dd})$, the red line, and $P(w|\mbox{dw})$, the green line.
We note that the green line has much the same shape as the
blue line but with a substantial offset.

<<fig=TRUE,echo=FALSE>>=
off=get_offset(zaza_pbs[,"P(w|dw)"],zaza_pbs[,"#dw"],zaza_pbs[,"P(w|d)"],zaza_pbs[,"#w"])[[2]]
plot(fit_probs(zaza_pbs[,"P(w|d)"],zaza_pbs[,"#d"],order=4)[[1]]+off,
type="l",xlab="day",ylab="probability",col="blue",ylim=c(0,.8))
lines(fit_probs(zaza_pbs[,"P(w|dw)"],zaza_pbs[,"#dw"],order=4)[[1]],col="green")
@

Here we see $P(w|\mbox{d})$ (the blue line) shifted to match
$P(w|\mbox{dw})$ (the green line).  It seems that we can use
the shifted blue line rather than the green line.  Given that we have
much more confidence in the shifted blue line (more data, fewer coefficients)
that the green line, we may prefer to use the shifted blue line.

\section{Parameter Files}

On way of creating a model is to start with a set of raw probabilities,
{\tt raw\_probs}, derived from a dataset associated (usually) with a station.
Then each curve $P(w|\mbox{lag})$ can be a fitted version of the corresponding
data in the dataset, or a (possibly shifted) fitted version of some other
data from the dataset.

The model is described by a {\tt parameter (*.pl)} file.
An example of the start of such a file is given.

\begin{verbatim}
<order> = 2
<dd> = dd  
<dd_fit_order>= choose
<dd_offset> = NO
...
\end{verbatim}

Every line has the form
\begin{verbatim}
<key> = value
\end{verbatim}
When read in you get a list, with {\tt list[key] = value}
with value a string.

The first parameter, {\tt order}, gives the order of the wet/dry part
of the model.  For each of the $2^{\mbox{order}}$ values for the {\tt lag},
there are three parameters.   The first {\tt lag} is the column
of the raw dataset used; the second {\tt lag\_fit\_order} is the number
of harmonics used to fit the raw data (if this value is {\tt choose} then the fit
order is determined automatically); the third {\tt lag\_offset}
is the dataset from which the offset is to be determined, if the
value is {\tt NO} then there is no offset.

The part of the parameter file which deals with the amount of rain on wet
days is similar,  although in this case we have {\tt lag}
for the mean and standard deviation.

\begin{verbatim}
<rain_order>= 1
<rw>=w
<rw_fit_order>=4
<rw_offset> = NO
...
\end{verbatim}

This is the "standard" parameter file, {\tt order\_2\_0.pl}.   It describes an order 2
model for the probability of rain, and an order zero model for the
amount of rain.

\begin{verbatim}
<order> = 2
<dd> = dd  
<dd_fit_order>= 4
<dd_offset> = NO
<dw> = dw
<dw_fit_order>= 4
<dw_offset> = NO
<wd>= wd
<wd_fit_order>= 4
<wd_offset> = NO
<ww> = ww
<ww_fit_order>= 4
<ww_offset> = NO

rain_order>= 0
<r0_fit_order>= 4

\end{verbatim}

If we want an order 1 model for the amount of rain, we change only
the rain section (last three line) to 

\begin{verbatim}
<rain_order>= 1
<rw>=w
<rw_fit_order>=4
<rw_offset> = NO
<rd>=d
<rd_fit_order>=4
<rd_offset> = NO
\end{verbatim}

We can get a mixed markov model by  changing what is used to estimate
higher order lags.

\begin{verbatim}
<order> = 2
<dd> = d  
<dd_fit_order>= 4
<dd_offset> = NO
<dw> = d
<dw_fit_order>= 4
<dw_offset> = NO
<wd>= wd
<wd_fit_order>= 4
<wd_offset> = NO
<ww> = ww
<ww_fit_order>= 4
<ww_offset> = NO


<rain_order>= 0
<r0_fit_order>= 4
\end{verbatim}

Note that the curves for the order two lags dd and dw are both derived 
from the order 1 curve lag d.  However, the curves for the order 2
lags wd and ww are derived from order two curves.  In other words we only
use order 2 lags if the first day is wet.

We can add offsets if desired.  Let us change the offset for the curve
for lag dw.

\begin{verbatim}
<dw> = d
<dw_fit_order>= 4
<dw_offset> = dw
\end{verbatim}

Note that we still derive the curve from the first order lag,
but now we add an offset derived from the second order lag.

We can illustrate this by using the above data set.
(here we are looking a only the probability of rain)

First we show a second order model

<<fig=TRUE>>=
mod=make_approx_model_pl(zaza_pbs,"/home/william/Reading/rstudio/Climarkplus/inst/parameter/order_2_0.pl")
plot_model(mod,"Second Order Model")
@

As we have noted above, the wd, and ww, lines are not close
in shape to the w line, but the dd and dw lines are close in
shape to the d line.   So we can try a mixed model, going
to order 2 lags if the previous day was wet, but using only
order 1 if the previous day was dry

<<fig=TRUE>>=
mod=make_approx_model_pl(zaza_pbs,"/home/william/Reading/rstudio/climate/trunk/inst/parameter/order_2_(2_1)_0.pl")
plot_model(mod,"Mixed Model (wet 2, dry 1) ")
@

Note that {\tt P(w|dw)} and {\tt P(w|dd)} are identical.  The latter
obscures the former.

We note from above that the d line can be used for dd
but while the dw line is similar in shape to dd there is an
obvious offset.   We can include this offset.

<<fig=TRUE>>=
mod=make_approx_model_pl(zaza_pbs,"/home/william/Reading/rstudio/climate/trunk/inst/parameter/offset.pl")
plot_model(mod,"Mixed Model (wet 2, dry 1) dw offset")
@

Note that the dw line is now visible.  It has the same shape as
the dd (and hence d) line, but not the same offset.


\subsection{Fitting}

There are two functions that do the true
fitting:  {\tt fit\_rainy} for the probability of rain;
and {\tt fit\_amount} for the amount of rain.
Both functions take the same parameters
\begin{description}
\item[wms]  This is the raw data.  It must have column DOY and it
must have columns for the needed Markov lags
\item[filename]  The name of the parameter file used to guide the fit.
                  Standard parameter files can be founc in {\tt inst/parameter}
\item[others]  This is a vector of names of other predictors that should be
               used in the fit (no interactions).  Anything in others should
               also be a column in the raw data.
\item[other\_model\_string]  This can be anything you want.  It is a string
               that is added verbatim to the fitting string.  This can be used
               e.g. to study interactions.   However, if this is used the
               fit object produced probably cannot be used to construct a model
               for synthesis
\end{description}  

The output of both functions is a {\tt fit\_object}.  This is a list
of two items.  The first is a list of information, the second is
the fit, an R object.  

An example

<<>>=
fit_object_1=fit_rainy(zaza_wm,filename="/home/william/Reading/rstudio/Climarkplus/inst/parameter/order_2_0.pl")
fit_object_1[[1]]
summary(fit_object_1[[2]])
@

We see that the first member of the information list is the contents
of the parameter file.  The fit is the second member, summary gives
the coefficients in a nice form.  Note that the coefficients are
Fourier Coeffiencts for the levels of ULAGS.  ULAGS is a new column
added to the raw data.
It is similar to lags\_n  (n the order of the Markov fit)
but some lags may be combined  (not in
this example though)

We can experiment with adding something to the {\tt others} parameter.
First make a column of the Julian Day and add it to zaza\_wm

<<>>=
Julian = julian(as.Date(zaza_wm$Date))
zaza_wm["Julian"]=Julian
head(zaza_wm)
@

We can now add Julian as a predictor

<<>>=
fit_object_1a=fit_rainy(zaza_wm,filename="/home/william/Reading/rstudio/Climarkplus/inst/parameter/order_2_0.pl",others="Julian")
summary(fit_object_1a[[2]])
@


We note that the coefficient of "Julian" is significant
at the 5\%
level.  Furthermore, looking at the coefficient (4.75e-06) and
the mininum and maximum values of Julian, we note that the
net change over time is about 0.15.  This is in logit space,
the net change in probability is about .03, about a 6\%
change in probability.

We can also add something to the {\tt other\_model\_string}
parameter.  Lets look at the interactions of Julian with
the lags
<<>>=
fit_object_1b=fit_rainy(zaza_wm,filename="/home/william/Reading/rstudio/Climarkplus/inst/parameter/order_2_0.pl",others="Julian",other_model_string="ULAGS:Julian")
summary(fit_object_1b[[2]])
@
There is no significant interaction of Julian with any of the lags.
(Note that fit\_object\_1b is not suitable for making a model)

We can also fit the amounts.  Note that we use Gamma regression
(we used logistic regression for {tt fit\_rainy}).  As well
we only fit on days wich are rainy

<<>>=
fit_object_2=fit_amounts(zaza_wm,filename="/home/william/Reading/rstudio/Climarkplus/inst/parameter/order_2_0.pl")
summary(fit_object_2[[2]])
@

Note that as we are using a rain order of 0, there is no
interaction of the Fourier coefficients and any lag.



\subsection{The model}

Central to the package is the {\tt model} data set.  
There are functions to create models (e.g. from known data).

We can create a model from the fit objects produced above.

<<>>=
zaza_mod=make_model_from_fit_objects(fit_object_1,fit_object_2)
head(zaza_mod)
@

[Note that the model can and probably will change]
The data set has 366 rows,
only the first 6 are shown.  The first column contains
some information about the model.  The {\tt $<$rain$>$}
column contains the mean of the Gamma distribution of
the amount of rate.  The shape is constant and is given
in the firt column.  Columns of the form {\tt P(w|lag)}
are the Markov probabilities of rain.

\subsection{Simple Fitting For Model Choice}

We count for each day of year:the number of "w" days following
two "d" days; the number of "w" days following a "d" then a "w"
day etc.  Dividing by e.g. the number of times we have two consecutive
"d" days give the estimated probability.  The function {\tt make\_all\_probs}
does this, for all lags up to order  (default 2).
As well, for each day of year, we determine the mean and standard
deviation of the rain of a "w" day both unconditional, and conditioned
on lags up to {\tt max\_mean\_rain\_order} (default 1)

<<eval=FALSE>>=
  zaza_pbs=make_all_probs(zaza_wm)
@

<<>>=
head(zaza_pbs)
@


As we can see from a plot, the probabilities are all over the map.
In this form they will not help use to choose a good
model
<<fig=TRUE>>=
  plot(zaza_pbs[,"P(w|ww)"],xlab="Day of Year",ylab="P(w|ww)")
@

We need to smooth the probabilities.
We fit a Fourier series (this
                         has the advantage that we can make things periodic with period 1 year).
The order of the fit can be determined before hand or determined
interactively or automatically.
The function used is {\tt make\_approx\_model\_pl}.

<<>>=
  zaza_approx = make_approx_model_pl(zaza_pbs,"/home/william/Reading/rstudio/climate/trunk/inst/parameter/order_2_0.pl")
@ 

When fitting to obtain the approximate model , we weight each estimate by the number of observations used to
obtain the estimate.  So estimates based on only a single day (e.g. two
                                                               consecutive "w" days during the dry season) are not given much weight.   

<<fig=TRUE>>=
  plot(zaza_approx[,"P(w|ww)"],xlab="Day of Year",ylab="P(w|ww)")
@

And things look much smoother.  


\subsection{Interactive}


We can also do the fitting interactively.  At the console, enter the command
<<eval=FALSE>>=
  zaza_mod = make_model_general(zaza_pbs,inter=TRUE)
@
We see a graph 

\begin{figure}[h!]
\centering
\includegraphics{/home/william/Reading/rstudio/climate/inter_plot1.jpeg}
\end{figure}

The red circles represent data points.  The are of each circle is proportional
to the weighting the data point has in the fit.  The smallest circles are
data point calculated from a single line of the raw data 
(so for probabilities are 0 or 1).

The blue line represents the fitted curve.  It will change when we change
the order of the Fourier fit.

On the console you will see:
  
  \begin{figure}[h!]
\centering
\begin{verbatim}
enter

a:  use this fit
b:  use previous order
f:  add one to order
k:  set order to k
\end{verbatim}
\end{figure}
To enter a value you must type the value into the console and then press
return.  Entering a number changes the fit order to that number.  Try entering
8.  You get:
  
  \begin{figure}[H]
\centering
\includegraphics{/home/william/Reading/rstudio/climate/inter_plot2.jpeg}
\end{figure}

The fit does not look that much better, especially when considering
how much more wavy the line is.  Try entering 1.  You get:
  
  \begin{figure}[H]
\centering
\includegraphics{/home/william/Reading/rstudio/climate/inter_plot3.jpeg}
\end{figure}


Clearly we are now underfitting.   Enter 4, to get back to the first graph,
then enter {\tt a} to accept this fit.  You will then have 5 more graphs
to fit. Play around with the {\tt a,b} and {\tt f} keys or enter numbers.
Repeatedly pressing {\tt a} will use the default.

\subsection{Synthetic Data}

Once we have a model, we can use it to synthesize data.  The command is

<<>>=
  #load("zaza_synth")
  zaza_synth=synth_data_set_mod(zaza_mod,num_years=83)
  head(zaza_synth)
@
The data will start from year 1970 by default.  The number
of years produced is limited by your patience (and by the address space of your
                                               machine,  200,000 years for a 32 bit machine; you need to have a {\bf LOT} of patience to reach the limit if you 
                                               have a 64 bit machine).
As a rule of thumb 1000 years takes about a minute (your mileage will vary).

Let's compare the synthetic and the real data.  Clearly we cannot expect
day by day comparisons to be equal, indeed, compare the rain in 1931, to the first year of rain in the synthetic data.

<<fig=TRUE>>=
plot(zaza$Rain[93:459],xlab="Day of Year",ylab="mm Rain")
points(zaza_synth$Rain[1:366],col="green")
@

The exact values are different, but the pattern is similar.
We now take advantage of the r function {\tt x\_split=split(x,y)}
where x and y are in the same dataframe.  What this gives is a list
indexed by the values of y.  Each element contains every value
of x with the given value of y.  So {zaza\_split=split(zaza\_doy$Rain,zaza\_doy$DOY)}
is a list of 366 vectors. {\\tt zaza\_split[["120"]]} is a vector of all rainfall
on Day of Year 120.  So {\tt mean(zaza\_split[["120"]],na.rm=TRUE)} is the mean
rainfall on day 120 (the last arg means ignore NA's).  We take further advantage by using the r function {\tt sapply(list, function,args)} which applies  function
to every element of list, passing args to function.  So
{\tt sapply(zaza\_split,mean,na.rm=TRUE)} is a vector of the average rainfalls.
Comparing

<<fig=TRUE>>=
  zaza_split=split(zaza_doy$Rain,zaza_doy$DOY)
synth_split=split(zaza_synth$Rain,zaza_synth$DOY)
plot(sapply(zaza_split,mean,na.rm=TRUE),xlab="Day of Year",
     ylab="Average Rain mm.")
points(sapply(synth_split,mean,na.rm=TRUE),col="green")
@

The fit looks good on the mean, but we note that the variablity
for the simulated data seems a bit lower that that of the real data.

\subsection{Yearly Stats}

If we split our real or synthetic data set by {\tt mod\_year}
then we get a list of datasets, each covering a specific year. We can then
find things such a the average spell length (over years), the maximum dry spell
for each year etc.  There is a simple function to split by {\tt mod\_year}
adding the year it if it does not exist.  The function {\tt add\_spell\_info} calculates
and adds the length of wet and dry spells.
This should be applied before splitting if spells should cross year boundaries.
Note that we need to add the Markov stuff before adding spell info.

<<>>=
  synth_wm= add_markov(zaza_synth)
synth_spell= add_spell_info(synth_wm)
zaza_spell=add_spell_info(zaza_wm)
synth_split=split_by_year(synth_spell,year_begins_in_july=TRUE)
zaza_split=split_by_year(zaza_spell,year_begins_in_july=TRUE)
length(synth_split)
head(synth_split[["1981"]])
nrow(synth_split[["1981"]])
length(zaza_split)
head(zaza_split[["1951"]])
nrow(zaza_split[["1951"]])
@

So  {\tt synth\_split} consists of 84 data sets (there is a partial
                                                 year at the beginning and end) and {\tt zaza\_split}
consists of 82 data sets (there are no partial years.)

\subsubsection{Spell Lengths}

We can look at the average dry spell length.  For this we use the data
that has not been spit into years.  First we take only dry spells.
To do this, take only rows of {\tt zaza\_spell} that correspond to a dry
day.  

<<>>=
  zaza_dry=zaza_spell[(zaza_spell$wet_or_dry=="d"),]
head(zaza_dry)
@

Now we split the spell lengths by day of year, 
then take the mean (ignoring NA's).  Plot this
                    
<<fig=TRUE>>=
dry_spell_split=split(zaza_dry$spell_length,zaza_dry$DOY)
plot(sapply(dry_spell_split,mean,rm.na=T),type="l",xlab="Day of Year",
                    ylab="Days",main="Mean Length of Dry Spell")
@
                    
                    Note this is the average length of a dry spell, given that there
                    is a dry spell.  This may or may not be what you want.  If you want
                    the mean dry spell length, taking the dry spell length of a wet day
                    to be 0 then this can be done by adding another column.
                    
<<fig=TRUE>>=
zaza_spell$dry_spell_length=zaza_spell$spell_length
zaza_spell$dry_spell_length[zaza_spell$wet_or_dry == "w"]=0
zaza_spell$dry_spell_length[is.na(zaza_spell$wet_or_dry)]=NA
zaza_spell_dry_split=split(zaza_spell$dry_spell_length,zaza_spell$DOY)
plot(sapply(zaza_spell_dry_split,mean,na.rm=T),type="l")
@

                    This looks similar.  Plot them together for comparison.  (note the use of
                    the {\tt lines} function which adds lines to a graph)
                    
<<fig=TRUE>>=
plot(sapply(dry_spell_split,mean,rm.na=T),type="l",xlab="Day of Year",
                    ylab="Days",main="Mean Length of Dry Spell")
                    lines(sapply(zaza_spell_dry_split,mean,na.rm=T),col="green")
@
                    
                    Assume that we know our crop can withstand dry spells of up to 
                    5 days.  Then we are interested in the probability of a dry spell
                    of more than 5 days.  
                    
<<fig=TRUE>>=
zaza_dry_spell_over_5=zaza_spell[zaza_spell$wet_or_dry=="d" & zaza_spell$spell_length > 5,]
zaza_dry_spell_over_5_split=split(zaza_dry_spell_over_5,zaza_dry_spell_over_5$DOY)
 num_of_dry_spells_over_5=sapply(zaza_dry_spell_over_5_split,nrow)
zaza_spell_good=zaza_spell[!is.na(zaza_spell$wet_or_dry),]
zaza_spell_good_split=split(zaza_spell_good,zaza_spell_good$DOY)
num_good_days=sapply(zaza_spell_good_split,nrow)
prob_of_dry_spell_over_5=num_of_dry_spells_over_5/num_good_days
plot(prob_of_dry_spell_over_5,type="l",xlab="Day of Year",ylab="prob",
main="Probability of a dry spell of more than 5 days")
@
                    
                    Naturally, all the above can be done with synthetic data as well.
                    (Indeed, this is the whole point.  Get your model from 20 years of
                    real data, but get your probabilities from 100 or 1000 years of
                    synthesized data.  In some cases, the actual value can be obtained
                    from the model by clever analysis (e.g. Markov model's and spell probabilities). 
However, R is cheap and fast; Statisticians capable of doing the analyses
are expensive and slow.  And what happens when you modify your
model?)

\subsubsection{First Day of Growing Season}

Two common definitions of the "First Day of the Growing Season" are:
  
  \begin{enumerate}
\item  The first day of a period of n rainy days on which there is more than k
millimetres of rain in total
\item  As (1.) but additionally, there is no dry spell of k days in the next
j days
\end{enumerate}

The second definition may be defined as the time of successful planting
(young seedlings may be injured or killed by a dry spell of k days)
The function {\tt fdgs} can calculate either of these for a year
of data.  So if we apply it to every year of data to find the distribution
of the "First Day of the Growing Season"  (we start our search in July
                                           if the growing season occurs in "winter").  So:
  
<<>>=
first_days=sapply(zaza_split,fdgs)
first_days_succ=sapply(zaza_split,fdgs,type=2)
@

and we can do the same thing with synthetic data

<<>>=
first_days_synth=sapply(synth_split,fdgs)
first_days_succ_synth=sapply(synth_split,fdgs,type=2)
@

In this case a histogram is best for viewing a comparison.

<<fig=TRUE>>=
  hist(first_days,breaks=25,col="red",density=10,
       xlab="Day of Year",main="First Day of Growing Season")
@
We can compare this with the calculations from the synthetic data
(note for adding information to a histogram, use the {\tt add=T})
parameter.

<<fig=TRUE>>=
  hist(first_days,breaks=25,col="red",density=10,
       xlab="Day of Year",main="First Day of Growing Season")
hist(first_days_synth,breaks=25,col="green",density=5,add=T)
@

Again, this is similar but not identical.

Another question we might ask is:  "In how many of the 82 years
was planting by definition 1. successful?"
To answer this we can compare, {\tt first\_days}
and {\tt first\_days\_succ}.  We need to be careful to allow
for NA's and for modding by 366.

<<>>=
diff=(first_days_succ-first_days) %% 366
diff_no_na=diff[!is.na(diff)]
diff_good=diff_no_na[diff_no_na==0]
length(diff_good)/length(diff_no_na)
@

This suggests that the default values do not work
well for this site. Perhaps a more drought tolerant crop
would work better, or wait for more rain before saying
the growing season has started.

\end{document}